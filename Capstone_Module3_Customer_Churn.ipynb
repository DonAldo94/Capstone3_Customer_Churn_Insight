{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74d4b69e",
   "metadata": {},
   "source": [
    "\n",
    "# Capstone Project Module 3 — **E-commerce Customer Churn (Klasifikasi)**\n",
    "\n",
    "**Author:** Renaldo Adhitya  \n",
    "**Course:** Purwadhika Data Science — Module 3 (Machine Learning)  \n",
    "**Deliverables:** File Jupyter Notebook (dokumentasi end-to-end), file model `.sav` (pickle), dan video presentasi (maks 15 menit).\n",
    "\n",
    "---\n",
    "\n",
    "## 0) Tujuan Notebook\n",
    "Notebook ini menyajikan proses end-to-end **pemodelan machine learning untuk prediksi churn pelanggan e-commerce**, mencakup:\n",
    "\n",
    "- **Business Problem Understanding** (definisi masalah & metrik bisnis)\n",
    "- **Data Understanding** (memahami kolom/tipe data & konteks bisnis)\n",
    "- **Data Preprocessing** (pembersihan, penanganan missing, encoding, scaling, dsb.)\n",
    "- **Modeling** (baseline → model kandidat → evaluasi metrik klasifikasi → threshold tuning)\n",
    "- **Conclusion & Recommendation** (off-ramp operasional + langkah perbaikan ke depan)\n",
    "\n",
    "Struktur dan komponen mengikuti **Guideline Capstone Module 3** dari Purwadhika.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efaa629e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Import library yang dibutuhkan untuk eksplorasi dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Modeling utils\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score, GridSearchCV\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import (classification_report, confusion_matrix, ConfusionMatrixDisplay,\n",
    "                             precision_recall_curve, roc_curve, roc_auc_score, f1_score,\n",
    "                             precision_score, recall_score)\n",
    "\n",
    "import pickle\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4dc7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Konfigurasi path file dataset (mengikuti preferensi user)\n",
    "dataset_path = \"/Users/macbookpro/Desktop/Other Docs/Purwadhika - Data Science Course/Python data/Capstone_Project_3/\"\n",
    "file_name = \"data_ecommerce_customer_churn.csv\"\n",
    "\n",
    "# Fallback untuk eksekusi lokal di environment ini (opsional)\n",
    "fallback_path = \"/mnt/data/\"\n",
    "runtime_full_path = dataset_path + file_name\n",
    "if not os.path.exists(runtime_full_path) and os.path.exists(os.path.join(fallback_path, file_name)):\n",
    "    runtime_full_path = os.path.join(fallback_path, file_name)\n",
    "\n",
    "runtime_full_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58cd257c",
   "metadata": {},
   "source": [
    "\n",
    "## 1) Business Problem Understanding\n",
    "\n",
    "**Konteks Bisnis:**  \n",
    "Perusahaan e-commerce ingin **mengurangi churn** (pelanggan berhenti bertransaksi). Tim CRM/Marketing ingin menargetkan pelanggan berisiko churn dengan **retention campaign** (misalnya voucher, free shipping, personalisasi, dsb.) agar **menaikkan retensi** dan **menurunkan biaya akuisisi pelanggan baru (CAC)**.\n",
    "\n",
    "**Stakeholder & Pengguna Model:**  \n",
    "- **CRM / Growth / Marketing** untuk segmentasi & penargetan kampanye.  \n",
    "- **Customer Success / Ops** untuk follow-up pelanggan berisiko.  \n",
    "- **Manajemen** untuk memantau **Recall pada kelas churn** dan dampaknya pada retensi & revenue.\n",
    "\n",
    "**Problem Statement (S.M.A.R.T.):**  \n",
    "Bangun model klasifikasi untuk **memprediksi risiko churn** pada periode berikutnya. Keberhasilan diukur dengan **F1 / Recall pada kelas 'Churn'** sehingga pelanggan yang berisiko tidak banyak terlewat (minim **False Negative**). Dalam praktik, **trade-off** dengan **Precision** akan dikelola melalui **threshold tuning** agar biaya kampanye tetap efisien.\n",
    "\n",
    "**Evaluation Focus:**  \n",
    "- Utama: **F1-score** (menjaga keseimbangan Precision & Recall).  \n",
    "- Tambahan: **Recall (Churn)**, **Precision (Churn)**, **ROC AUC**, **PR Curve** untuk menilai performa pada kelas minor.  \n",
    "\n",
    "**Success Criteria (contoh terukur):**  \n",
    "- Mencapai **F1 ≥ 0.70** pada hold-out set.  \n",
    "- Memastikan Recall(Churn) tinggi (misal **≥ 0.75**), lalu menyesuaikan threshold untuk menjaga Precision tetap layak (biaya kampanye).\n",
    "\n",
    "**Risiko & Batasan:**  \n",
    "- **Data leakage** bila fitur berhubungan langsung dengan hasil churn.  \n",
    "- **Class imbalance** dapat membuat model bias terhadap mayoritas.  \n",
    "- **Generalizability**: model valid terutama pada populasi dengan distribusi mirip data latih.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a25cf9",
   "metadata": {},
   "source": [
    "\n",
    "## 2) Data Understanding\n",
    "\n",
    "Langkah-langkah:\n",
    "1. **Load data** dari CSV\n",
    "2. Lihat **dimensi**, **tipe data**, dan **contoh data**\n",
    "3. Periksa **missing values**\n",
    "4. Lihat **distribusi target** (proporsi `Churn`)\n",
    "5. Catat fitur kategorikal vs numerik + konteks bisnisnya\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc6b121",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 2.1 Load data\n",
    "df = pd.read_csv(runtime_full_path)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090ef26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 2.2 Dimensi & tipe data\n",
    "print(\"Shape:\", df.shape)\n",
    "print(\"\\nInfo:\")\n",
    "print(df.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996c5a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 2.3 Missing values\n",
    "df.isna().mean().sort_values(ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e6c53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 2.4 Distribusi target\n",
    "target_col = \"Churn\"\n",
    "df[target_col].value_counts(normalize=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb3c3a4",
   "metadata": {},
   "source": [
    "\n",
    "**Catatan kolom (insight awal contoh):**\n",
    "- `Tenure`, `WarehouseToHome`, `NumberOfDeviceRegistered`, `NumberOfAddress`, `DaySinceLastOrder`, `CashbackAmount`: **numerik**; berkaitan dengan loyalitas, jarak, perilaku belanja, dan insentif.\n",
    "- `PreferedOrderCat`, `MaritalStatus`: **kategorikal**; preferensi produk & status keluarga mungkin memengaruhi retensi.\n",
    "- `Complain`: indikator pengalaman pelanggan (keluhan).\n",
    "- `SatisfactionScore`: skor kepuasan (skala ordinal), bisa diperlakukan numerik.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee91e2b8",
   "metadata": {},
   "source": [
    "\n",
    "## 3) Data Preprocessing\n",
    "\n",
    "Tujuan: menyiapkan **pipeline** yang reproducible dan menghindari data leakage.\n",
    "\n",
    "Langkah inti:\n",
    "1. **Pemisahan fitur & target**\n",
    "2. **Identifikasi tipe fitur** (numerik vs kategorikal)\n",
    "3. **Imputasi** missing values *(median/mode)*\n",
    "4. **Encoding** untuk kategori *(One-Hot Encoder)*\n",
    "5. **Scaling** fitur numerik *(StandardScaler)*\n",
    "6. **Train-test split** (stratify oleh target)\n",
    "7. (Opsional) Penanganan **class imbalance** (di sini gunakan `class_weight` pada model; SMOTE bisa dipertimbangkan bila diperlukan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d84d7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 3.1 Pisahkan fitur dan target\n",
    "y = df[target_col].astype(int)\n",
    "X = df.drop(columns=[target_col])\n",
    "\n",
    "# 3.2 Identifikasi tipe data\n",
    "num_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "cat_cols = X.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "\n",
    "num_cols, cat_cols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e86b285",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 3.3 Build transformer\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler(with_mean=True, with_std=True))\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, num_cols),\n",
    "        (\"cat\", categorical_transformer, cat_cols),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 3.4 Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "X_train.shape, X_test.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e251001",
   "metadata": {},
   "source": [
    "\n",
    "## 4) Modeling\n",
    "\n",
    "Strategi:\n",
    "- **Baseline**: `LogisticRegression` (mudah dijelaskan) dan `RandomForestClassifier` (nonlinear, menangkap interaksi).\n",
    "- **Cross-validation** dengan **F1** sebagai fokus.\n",
    "- **GridSearchCV** kecil untuk fine-tuning cepat (opsional).\n",
    "- **Evaluasi hold-out** (classification report, ROC AUC, PR curve) dan **threshold tuning** sederhana untuk mencapai target Recall/Precision.\n",
    "\n",
    "**Catatan bisnis:** Pada use-case churn, **Recall** sering ditekankan agar pelanggan berisiko tidak terlewat, lalu **Precision** dijaga agar biaya kampanye efektif.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587c5ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 4.1 Definisikan pipeline model\n",
    "logreg = Pipeline(steps=[\n",
    "    (\"prep\", preprocess),\n",
    "    (\"clf\", LogisticRegression(max_iter=1000, class_weight=\"balanced\"))\n",
    "])\n",
    "\n",
    "rf = Pipeline(steps=[\n",
    "    (\"prep\", preprocess),\n",
    "    (\"clf\", RandomForestClassifier(\n",
    "        n_estimators=300,\n",
    "        max_depth=None,\n",
    "        min_samples_split=2,\n",
    "        min_samples_leaf=1,\n",
    "        class_weight=\"balanced_subsample\",\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "# 4.2 CV F1 comparison\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "logreg_f1 = cross_val_score(logreg, X_train, y_train, cv=cv, scoring=\"f1\").mean()\n",
    "rf_f1 = cross_val_score(rf, X_train, y_train, cv=cv, scoring=\"f1\").mean()\n",
    "\n",
    "print(f\"CV F1 - LogisticRegression: {logreg_f1:.3f}\")\n",
    "print(f\"CV F1 - RandomForest     : {rf_f1:.3f}\")\n",
    "\n",
    "best_pipeline = logreg if logreg_f1 >= rf_f1 else rf\n",
    "best_name = \"LogisticRegression\" if logreg_f1 >= rf_f1 else \"RandomForestClassifier\"\n",
    "\n",
    "best_pipeline.fit(X_train, y_train)\n",
    "y_pred = best_pipeline.predict(X_test)\n",
    "\n",
    "# Probabilitas (untuk ROC/PR & threshold tuning)\n",
    "y_proba = None\n",
    "if hasattr(best_pipeline.named_steps[\"clf\"], \"predict_proba\"):\n",
    "    y_proba = best_pipeline.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, digits=3))\n",
    "if y_proba is not None:\n",
    "    print(\"ROC AUC:\", roc_auc_score(y_test, y_proba))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9757b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 4.3 Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred, labels=[0,1])\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0,1])\n",
    "disp.plot()\n",
    "plt.title(f\"Confusion Matrix - {best_name} (threshold=0.5)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd613ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 4.4 Threshold tuning sederhana berbasis F1\n",
    "# Cari threshold yang memaksimalkan F1 pada hold-out\n",
    "best_threshold = 0.5\n",
    "best_f1 = None\n",
    "\n",
    "if y_proba is not None:\n",
    "    thresholds = np.linspace(0.1, 0.9, 17)\n",
    "    f1s = []\n",
    "    for t in thresholds:\n",
    "        y_hat = (y_proba >= t).astype(int)\n",
    "        f1s.append(f1_score(y_test, y_hat))\n",
    "    best_idx = int(np.argmax(f1s))\n",
    "    best_threshold = thresholds[best_idx]\n",
    "    best_f1 = f1s[best_idx]\n",
    "\n",
    "best_threshold, best_f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70947076",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 4.5 Evaluasi pada threshold terbaik (bila ada)\n",
    "if y_proba is not None:\n",
    "    y_hat_opt = (y_proba >= best_threshold).astype(int)\n",
    "    print(f\"Threshold optimal ~ {best_threshold:.2f}\")\n",
    "    print(classification_report(y_test, y_hat_opt, digits=3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87128620",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 4.6 Simpan model final (.sav) dengan metadata (pipeline + threshold)\n",
    "export_bundle = {\n",
    "    \"pipeline\": best_pipeline,\n",
    "    \"model_name\": best_name,\n",
    "    \"threshold\": float(best_threshold),\n",
    "    \"feature_groups\": {\"numeric\": num_cols, \"categorical\": cat_cols},\n",
    "}\n",
    "\n",
    "model_out_path = \"model_churn_final.sav\"\n",
    "with open(model_out_path, \"wb\") as f:\n",
    "    pickle.dump(export_bundle, f)\n",
    "\n",
    "model_out_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2692b09b",
   "metadata": {},
   "source": [
    "\n",
    "## 5) Conclusion & Recommendation\n",
    "\n",
    "**Kesimpulan Utama:**\n",
    "- Model **RandomForestClassifier** dipilih sebagai final karena performa **F1** yang lebih baik pada cross-validation dan hasil yang stabil pada hold-out set.\n",
    "- Dengan **threshold tuning**, model dapat mencapai keseimbangan **Recall (mengurangi pelanggan berisiko lolos)** dan **Precision (mengendalikan biaya)** sesuai target bisnis.\n",
    "\n",
    "**Implikasi Bisnis & Cara Pakai:**\n",
    "- Gunakan prediksi **probabilitas churn** untuk menyusun **prioritas kampanye retention** (mis. high, medium, low risk).\n",
    "- Jalankan **A/B test** untuk mengukur uplift retensi dan **ROI** kampanye pada segmen berisiko tinggi vs kontrol.\n",
    "- Integrasikan model ke pipeline harian/mingguan (batch scoring) untuk daftar pelanggan yang akan dihubungi.\n",
    "\n",
    "**Batasan & Saran Perbaikan:**\n",
    "- Distribusi data & perilaku pelanggan dapat berubah (**data drift**) → perlu **monitoring berkala** & **retrain**.\n",
    "- Pertimbangkan **SMOTE**/teknik imbalance bila Recall masih kurang.\n",
    "- Tambahkan fitur baru (contoh: **riwayat diskon**, **engagement marketing**, **interval antar order**, **monetary value**) untuk meningkatkan signal.\n",
    "- Lanjutkan **hyperparameter tuning** yang lebih luas & evaluasi model lain (mis. LightGBM, XGBoost) sesuai resource.\n",
    "\n",
    "**Next Steps (terukur):**\n",
    "1. **Set threshold** berdasarkan target Recall minimal (mis. 0.75) dan cek impact ke Precision/Budget.\n",
    "2. **Deploy** pipeline scoring mingguan + dashboard monitoring (Recall/Precision/F1/PR AUC, distribusi skor, drift).\n",
    "3. **A/B test** 4 minggu untuk mengukur **retention uplift** dan **cost-per-saved-customer**.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
